
# 监控显存使用

`PyTorch`提供了两个函数用于显存查询：

* [memory_allocated](https://pytorch.org/docs/stable/cuda.html#torch.cuda.memory_allocated)
* [max_memory_allocated](https://pytorch.org/docs/stable/cuda.html?highlight=max_memory_allocated#torch.cuda.max_memory_allocated)

## memory_allocated

>torch.cuda.memory_allocated(device=None)

查询指定`GPU`中使用的显存大小（字节）

## max_memory_allocated

>torch.cuda.max_memory_allocated(device=None)

返回给定设备的张量占用的最大`GPU`内存（字节）